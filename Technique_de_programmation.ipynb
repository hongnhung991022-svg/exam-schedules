{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongnhung991022-svg/exam-schedules/blob/main/Technique_de_programmation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction : Le paradoxe de la transparence algorithmique\n",
        "\n",
        "Nous vivons une √©poque o√π YouTube pr√©tend nous offrir une exp√©rience \"sur mesure\", adapt√©e √† nos go√ªts personnels. Pourtant, cette personnalisation cache une r√©alit√© inqui√©tante : l'onglet \"Tendances\", autrefois visible par tous, a progressivement disparu au profit d'un flux algorithmique opaque. Nous avons l'impression de naviguer librement dans un oc√©an de contenus, alors que nous sommes guid√©s par des m√©canismes invisibles qui maximisent notre temps d'√©cran, souvent au d√©triment de notre bien-√™tre psychologique.\n",
        "\n",
        "**Probl√©matique**\n",
        "\n",
        "Si les tendances YouTube sont d√©sormais dissimul√©es derri√®re une interface hyper-personnalis√©e, leur influence sur nos comportements a-t-elle r√©ellement disparu ? Comment peut-on mesurer objectivement l'impact de ce flux invisible sur notre sant√© mentale alors m√™me que nous ne percevons plus son existence ? Notre projet r√©pond √† cette question cruciale : en utilisant les droits RGPD et la programmation Python, nous avons construit un outil d'audit qui rend visible l'invisible, r√©v√©lant si nous sommes, √† notre insu, synchronis√©s avec des tendances potentiellement toxiques pour notre √©quilibre mental."
      ],
      "metadata": {
        "id": "eAo87hx9dDRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code 1 : Installation et configuration initiale\n",
        "\n",
        "**Explication Technique**\n",
        "\n",
        "Ce premier code installe l'infrastructure logicielle n√©cessaire au projet. Il importe des biblioth√®ques Python essentielles : Pandas pour la manipulation de donn√©es tabulaires, Matplotlib et Seaborn pour la visualisation, et google-api-python-client pour communiquer avec l'API YouTube. La cl√© API permet d'authentifier les requ√™tes aupr√®s des serveurs Google.\n",
        "\n",
        "**Interpr√©tation Critique**\n",
        "\n",
        "Ce code mat√©rialise le principe d'appropriation des donn√©es personnelles. En installant ces outils, vous vous donnez les moyens techniques de \"contre-auditer\" les plateformes. C'est un acte de r√©sistance num√©rique : au lieu de subir passivement l'algorithme, vous cr√©ez votre propre outil d'analyse. L'utilisation de l'API YouTube est particuli√®rement significative car elle force Google √† vous r√©v√©ler des informations normalement cach√©es dans l'interface utilisateur, comme le classement r√©el des tendances par r√©gion."
      ],
      "metadata": {
        "id": "pGvlm7Ckapte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cellule 1 : Installation des outils\n",
        "!pip install pandas matplotlib seaborn google-api-python-client isodate"
      ],
      "metadata": {
        "id": "tKf2hDikrgCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code 2 : Analyse comportementale profonde\n",
        "\n",
        "**Explication Technique**\n",
        "\n",
        "Ce code charge le fichier watch-history.json issu de Google Takeout et enrichit chaque vid√©o avec des m√©tadonn√©es obtenues via l'API (cat√©gorie, dur√©e, nombre de vues, tags). Il impl√©mente un syst√®me de mise √† jour incr√©mentale : seules les nouvelles vid√©os sont analys√©es pour √©conomiser le quota API. Les visualisations produites incluent un graphique des cha√Ænes dominantes, une distribution horaire de visionnage, et une analyse de la popularit√© du contenu consomm√©.\n",
        "\n",
        "**Interpr√©tation Critique**\n",
        "\n",
        "Ce script r√©v√®le la \"chronobiologie de l'addiction\" mentionn√©e dans votre pr√©sentation orale. En cartographiant vos heures de consommation, il expose comment l'algorithme exploite vos moments de vuln√©rabilit√© (soir√©es, fins de semaine). Le graphique des cha√Ænes dominantes mat√©rialise votre \"bulle de filtre\" : si 80% de votre temps se concentre sur 5-10 cha√Ænes, vous √™tes dans une chambre d'√©cho algorithmique. L'analyse des vues (mainstream vs niche) est particuli√®rement r√©v√©latrice : consommer majoritairement du contenu viral indique une forte exposition aux m√©canismes de comparaison sociale et d'anxi√©t√© d√©crits dans les √©tudes psychologiques."
      ],
      "metadata": {
        "id": "0559HlnCa-Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "API_KEY = \"Ins√©rer votre cl√© API ici\" # √Ä ne jamais mettre sur Git ! Utilisez un fichier config ou env.\n",
        "DB_FILE = \"local_video_database.csv\"\n",
        "TAKEOUT_FILE = \"Ins√©rer votre fichier watch-history.json ici\" # Le fichier t√©l√©charg√© depuis Google\n",
        "\n",
        "# ==========================================\n",
        "# MODULE 1 : GESTION DES DONN√âES ET MISE √Ä JOUR\n",
        "# ==========================================\n",
        "\n",
        "def load_takeout_data(filepath):\n",
        "    \"\"\"Charge et nettoie les donn√©es brutes de Google Takeout.\"\"\"\n",
        "    print(f\"Chargement de {filepath}...\")\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Erreur : Fichier Takeout introuvable.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    clean_data = []\n",
        "    for entry in data:\n",
        "        # On ne garde que les entr√©es qui sont des vid√©os (pas les pubs ou visites de chaine)\n",
        "        if 'titleUrl' in entry and 'watch?v=' in entry['titleUrl']:\n",
        "            video_id = entry['titleUrl'].split('watch?v=')[1]\n",
        "            # Gestion de la date\n",
        "            watch_time = entry['time'] # Format ISO\n",
        "            clean_data.append({\n",
        "                'video_id': video_id,\n",
        "                'title': entry['title'].replace(\"Vous avez regard√© \", \"\"),\n",
        "                'watch_time': watch_time\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(clean_data)\n",
        "\n",
        "def get_video_details(video_ids, api_key):\n",
        "    \"\"\"Interroge l'API YouTube pour r√©cup√©rer les cat√©gories (Enrichissement).\"\"\"\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "    video_details = []\n",
        "\n",
        "    # L'API accepte max 50 IDs par requ√™te\n",
        "    chunk_size = 50\n",
        "    for i in range(0, len(video_ids), chunk_size):\n",
        "        chunk = video_ids[i:i+chunk_size]\n",
        "        request = youtube.videos().list(\n",
        "            part=\"snippet,contentDetails,statistics\",\n",
        "            id=','.join(chunk)\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            video_details.append({\n",
        "                'video_id': item['id'],\n",
        "                'category_id': item['snippet']['categoryId'],\n",
        "                'channel_title': item['snippet']['channelTitle'],\n",
        "                'tags': item['snippet'].get('tags', []), # Les tags sont cl√©s pour comprendre les tendances\n",
        "                'duration': item['contentDetails']['duration'],\n",
        "                'view_count': item['statistics'].get('viewCount', 0)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(video_details)\n",
        "\n",
        "def update_database(new_df):\n",
        "    \"\"\"M√©canisme de mise √† jour incr√©mentale.\"\"\"\n",
        "    # 1. Charger la base existante si elle existe\n",
        "    if os.path.exists(DB_FILE):\n",
        "        existing_db = pd.read_csv(DB_FILE)\n",
        "        print(f\"Base existante charg√©e : {len(existing_db)} vid√©os.\")\n",
        "    else:\n",
        "        existing_db = pd.DataFrame(columns=['video_id'])\n",
        "        print(\"Cr√©ation d'une nouvelle base de donn√©es locale.\")\n",
        "\n",
        "    # 2. Identifier les vid√©os inconnues (qu'on n'a pas encore analys√©es)\n",
        "    # On compare les IDs du Takeout avec ceux de la DB locale\n",
        "    merged = new_df.merge(existing_db, on='video_id', how='left', indicator=True)\n",
        "    unknown_videos = merged[merged['_merge'] == 'left_only']['video_id'].unique()\n",
        "\n",
        "    print(f\"Nouvelles vid√©os d√©tect√©es √† analyser via API : {len(unknown_videos)}\")\n",
        "\n",
        "    if len(unknown_videos) > 0:\n",
        "        # Attention aux quotas API (limitez si n√©cessaire pour les tests)\n",
        "        # Pour l'exemple, on limite √† 200 nouvelles vid√©os pour ne pas griller le quota gratuit\n",
        "        details_df = get_video_details(list(unknown_videos)[:200], API_KEY)\n",
        "\n",
        "        # Fusionner et sauvegarder\n",
        "        full_db = pd.concat([existing_db, details_df], ignore_index=True).drop_duplicates(subset=['video_id'])\n",
        "        full_db.to_csv(DB_FILE, index=False)\n",
        "        print(\"Base de donn√©es mise √† jour avec succ√®s.\")\n",
        "        return full_db\n",
        "    else:\n",
        "        print(\"Aucune nouvelle donn√©e API n√©cessaire.\")\n",
        "        return existing_db\n",
        "\n",
        "# ==========================================\n",
        "# MODULE 2 : ANALYSE ET VISUALISATION\n",
        "# ==========================================\n",
        "\n",
        "def analyze_trends(history_df, metadata_df):\n",
        "    \"\"\"Cr√©e les graphiques pour la pr√©sentation.\"\"\"\n",
        "\n",
        "    # Fusionner l'historique (QUAND j'ai regard√©) avec les m√©tadonn√©es (QUOI)\n",
        "    df = history_df.merge(metadata_df, on='video_id', how='inner')\n",
        "\n",
        "    # Convertir le temps\n",
        "    df['watch_time'] = pd.to_datetime(df['watch_time'], format='ISO8601') # Added format='ISO8601'\n",
        "    df['hour'] = df['watch_time'].dt.hour\n",
        "    df['day_of_week'] = df['watch_time'].dt.day_name()\n",
        "\n",
        "    # Configuration du style\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    # --- Graphique 1 : Ma \"Bulle\" (Cat√©gories) ---\n",
        "    # Note: L'API renvoie des ID de cat√©gories (ex: '10' = Music).\n",
        "    # Il faudrait une map compl√®te, ici simplifi√©.\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_channels = df['channel_title'].value_counts().head(10)\n",
        "    sns.barplot(x=top_channels.values, y=top_channels.index, palette=\"viridis\")\n",
        "    plt.title(\"Les 10 cha√Ænes qui dominent mon flux (Ma Bulle)\")\n",
        "    plt.xlabel(\"Nombre de vues\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Graphique 2 : Chronobiologie de l'addiction ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['hour'], bins=24, kde=True, color=\"red\")\n",
        "    plt.title(\"√Ä quelle heure l'algorithme me capte-t-il le mieux ?\")\n",
        "    plt.xlabel(\"Heure de la journ√©e (0-24)\")\n",
        "    plt.ylabel(\"Fr√©quence\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Graphique 3 : Mainstream vs Niche ---\n",
        "    # Analyse bas√©e sur le nombre de vues global des vid√©os regard√©es\n",
        "    df['view_count'] = pd.to_numeric(df['view_count'])\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x=df['view_count'])\n",
        "    plt.xscale('log') # √âchelle logarithmique car les vues varient √©norm√©ment\n",
        "    plt.title(\"Distribution des vues : Suis-je un consommateur de contenu 'Viral' ?\")\n",
        "    plt.xlabel(\"Vues totales de la vid√©o (√âchelle Log)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Charger l'historique brut\n",
        "    history = load_takeout_data(TAKEOUT_FILE)\n",
        "\n",
        "    if not history.empty:\n",
        "        # 2. Mettre √† jour les m√©tadonn√©es (API)\n",
        "        metadata = update_database(history)\n",
        "\n",
        "        # 3. Lancer l'analyse\n",
        "        analyze_trends(history, metadata)\n",
        "    else:\n",
        "        print(\"Veuillez placer le fichier watch-history.json dans le dossier.\")"
      ],
      "metadata": {
        "id": "VVL5Iprxr7KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code 3 : Audit d'influence directe (Score de Sensibilit√©)\n",
        "\n",
        "**Explication Technique**\n",
        "\n",
        "Ce code r√©cup√®re le Top 50 des vid√©os tendances en France via l'API, puis calcule l'intersection avec votre historique personnel. Il g√©n√®re deux diagrammes circulaires comparant les cat√©gories de contenu tendance versus vos cat√©gories personnelles. Le \"CATEGORY_MAP\" traduit les identifiants num√©riques YouTube en noms lisibles (Music, Gaming, Education, etc.).\n",
        "\n",
        "**Interpr√©tation Critique**\n",
        "\n",
        "C'est le c≈ìur de notre probl√©matique : \"Les tendances YouTube ont-elles cess√© de nous influencer si elles sont cach√©es ?\". Un score de 0% (comme dans vos r√©sultats) prouve que vous ne regardez aucune vid√©o du Top 50 actuel. Paradoxalement, cela ne signifie PAS que vous √™tes libre de l'influence algorithmique, mais plut√¥t que l'algorithme vous a hyper-personnalis√© au point de cr√©er une bulle √©tanche. Comme le pr√©cise votre oral, cette \"niche\" n'est pas protectrice : elle vous enferme dans un flux pr√©visible qui maximise votre engagement sans diversit√© cognitive. Les graphiques de cat√©gories r√©v√®lent si votre di√®te num√©rique est d√©s√©quilibr√©e (ex: 70% Entertainment, 5% Education).\n"
      ],
      "metadata": {
        "id": "6vnwk1ASbE27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from googleapiclient.discovery import build\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "API_KEY = \"Ins√©rer votre cl√© API ici# Collez votre cl√© ici\n",
        "TAKEOUT_FILE = \"Ins√©rer votre fichier watch-history.json ici\"\n",
        "# Liste de correspondance des ID et noms de cat√©gories (les plus courants)\n",
        "CATEGORY_MAP = {\n",
        "    \"1\": \"Film & Animation\",\n",
        "    \"2\": \"Autos & Vehicles\",\n",
        "    \"10\": \"Music\",\n",
        "    \"15\": \"Pets & Animals\",\n",
        "    \"17\": \"Sports\",\n",
        "    \"19\": \"Travel & Events\",\n",
        "    \"20\": \"Gaming\",\n",
        "    \"22\": \"People & Blogs\",\n",
        "    \"23\": \"Comedy\",\n",
        "    \"24\": \"Entertainment\",\n",
        "    \"25\": \"News & Politics\",\n",
        "    \"26\": \"Howto & Style\",\n",
        "    \"27\": \"Education\",\n",
        "    \"28\": \"Science & Technology\",\n",
        "    \"29\": \"Nonprofits & Activism\",\n",
        "    \"30\": \"Movies\",\n",
        "    \"43\": \"Shows\"\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# NOUVELLE FONCTION : AFFICHAGE DES CAT√âGORIES\n",
        "# ==========================================\n",
        "\n",
        "def display_category_table():\n",
        "    \"\"\"Affiche le tableau des ID et des noms pour la r√©f√©rence.\"\"\"\n",
        "    print(\"\\n--- TABLEAU DE R√âF√âRENCE DES CAT√âGORIES YOUTUBE ---\")\n",
        "    table_data = [[id, name] for id, name in CATEGORY_MAP.items()]\n",
        "    # Utilise tabulate pour un affichage propre\n",
        "    print(tabulate(table_data, headers=[\"ID\", \"Cat√©gorie\"], tablefmt=\"fancy_grid\"))\n",
        "\n",
        "def get_category_name(category_id):\n",
        "    \"\"\"Convertit un ID en nom de cat√©gorie.\"\"\"\n",
        "    return CATEGORY_MAP.get(category_id, f\"ID Inconnu ({category_id})\")\n",
        "\n",
        "# ==========================================\n",
        "# FONCTIONS D'ANALYSE (Reprise de la version pr√©c√©dente)\n",
        "# ==========================================\n",
        "\n",
        "def get_youtube_client():\n",
        "    return build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "def get_current_trending_videos(youtube):\n",
        "    \"\"\"R√©cup√®re les tendances actuelles.\"\"\"\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet,statistics\",\n",
        "        chart=\"mostPopular\",\n",
        "        regionCode=\"FR\",\n",
        "        maxResults=50\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    trending_list = []\n",
        "    for item in response['items']:\n",
        "        trending_list.append({\n",
        "            'video_id': item['id'],\n",
        "            'category_id': item['snippet']['categoryId']\n",
        "        })\n",
        "    return pd.DataFrame(trending_list)\n",
        "\n",
        "def load_my_history(filepath):\n",
        "    \"\"\"Charge et nettoie l'historique.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erreur : Fichier {filepath} introuvable.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    my_history = []\n",
        "    for entry in data:\n",
        "        if 'titleUrl' in entry and 'watch?v=' in entry['titleUrl']:\n",
        "            video_id = entry['titleUrl'].split('watch?v=')[-1][:11]\n",
        "            my_history.append({'video_id': video_id, 'date': entry['time']})\n",
        "    return pd.DataFrame(my_history).drop_duplicates(subset=['video_id'])\n",
        "\n",
        "def analyze_influence():\n",
        "    youtube = get_youtube_client()\n",
        "\n",
        "    df_trending = get_current_trending_videos(youtube)\n",
        "    df_my_history = load_my_history(TAKEOUT_FILE)\n",
        "\n",
        "    # √âtape 1 : Calculer l'intersection\n",
        "    videos_communes = df_my_history[df_my_history['video_id'].isin(df_trending['video_id'])]\n",
        "    nb_communs = len(videos_communes)\n",
        "\n",
        "    # √âtape 2 : R√©cup√©rer les cat√©gories de votre historique r√©cent\n",
        "    recent_ids = df_my_history['video_id'].head(50).tolist()\n",
        "    res = youtube.videos().list(part=\"snippet\", id=\",\".join(recent_ids)).execute()\n",
        "    my_categories_list = [item['snippet']['categoryId'] for item in res['items']]\n",
        "\n",
        "    df_my_cats = pd.DataFrame(my_categories_list, columns=['category_id'])\n",
        "\n",
        "    # --- Pr√©paration pour le graphique ---\n",
        "    df_trending['category_name'] = df_trending['category_id'].apply(get_category_name)\n",
        "    df_my_cats['category_name'] = df_my_cats['category_id'].apply(get_category_name)\n",
        "\n",
        "    # VISUALISATION\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    # Graphique 1 : Cat√©gories en Tendance (Noms affich√©s)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    # Utilisez 'category_name' pour les √©tiquettes\n",
        "    df_trending['category_name'].value_counts().plot(kind='pie', autopct='%1.1f%%', title=\"Cat√©gories en Tendance (France)\")\n",
        "    plt.ylabel('Proportion')\n",
        "\n",
        "    # Graphique 2 : Mes Cat√©gories (Noms affich√©s)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    df_my_cats['category_name'].value_counts().plot(kind='pie', autopct='%1.1f%%', title=\"Mes Cat√©gories (Audit Personnel)\")\n",
        "    plt.ylabel('Proportion')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # CONCLUSION\n",
        "    print(f\"\\n--- R√âSULTAT DE L'AUDIT ---\")\n",
        "    print(f\"Vous avez regard√© {nb_communs} vid√©os qui sont actuellement dans le Top 50 Tendances.\")\n",
        "    influence_score = (nb_communs / 50) * 100\n",
        "    print(f\"Votre indice d'influence directe est de : {influence_score:.1f}%\")\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display_category_table() # Affiche le tableau de r√©f√©rence au d√©but\n",
        "    analyze_influence()"
      ],
      "metadata": {
        "id": "MSD83O_wzuTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code 4 : Calcul du Score de Sensibilit√© (1-10)\n",
        "\n",
        "**Explication Technique**\n",
        "\n",
        "Ce code simplifie l'output pour produire un diagnostic binaire clair. Il calcule le pourcentage d'influence directe, puis le convertit en score sur 10 (formule : influence% / 5). Il ajoute une couche d'interpr√©tation automatis√©e selon trois paliers : Bulle de Niche (‚â§2), Influence Mod√©r√©e (3-5), Mainstream (‚â•6).\n",
        "\n",
        "**Interpr√©tation Critique**\n",
        "\n",
        "Votre score de 1.0/10 avec l'interpr√©tation \"Bulle de Niche\" illustre parfaitement le paradoxe que vous soulevez : l'algorithme vous conna√Æt \"trop bien\". Ce n'est pas une victoire, c'est une prison dor√©e. Les √©tudes montrent que l'hyper-personnalisation r√©duit la s√©rendipit√© et l'exposition √† des perspectives diverses, cr√©ant une forme d'isolement cognitif. Le message \"L'algorithme vous conna√Æt trop bien pour vous proposer du contenu grand public\" est ironique : cela signifie que vous √™tes devenu un profil \"rentable\" via une pr√©dictibilit√© maximale. Votre comportement est si bien mod√©lis√© que l'IA n'a plus besoin de tester de nouveaux contenus sur vous.\n"
      ],
      "metadata": {
        "id": "p08nlAQGbO27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from googleapiclient.discovery import build\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "API_KEY = \"Ins√©rer votre cl√© API ici\"  # <--- METTEZ VOTRE CL√â ICI\n",
        "TAKEOUT_FILE = \"Ins√©rer votre fichier watch-history.json ici\"\n",
        "\n",
        "# ==========================================\n",
        "# FONCTIONS TECHNIQUES\n",
        "# ==========================================\n",
        "\n",
        "def calculate_sensitivity_score(influence_percentage):\n",
        "    \"\"\"Calcule le score de 1 √† 10.\"\"\"\n",
        "    score = influence_percentage / 5\n",
        "    if score < 1: score = 1.0\n",
        "    if score > 10: score = 10.0\n",
        "    return round(score, 1)\n",
        "\n",
        "def get_current_trending_videos(youtube):\n",
        "    \"\"\"R√©cup√®re le Top 50 YouTube France.\"\"\"\n",
        "    try:\n",
        "        request = youtube.videos().list(\n",
        "            part=\"snippet,statistics\",\n",
        "            chart=\"mostPopular\",\n",
        "            regionCode=\"FR\",\n",
        "            maxResults=50\n",
        "        )\n",
        "        response = request.execute()\n",
        "        trending_list = [{'video_id': item['id'], 'category_id': item['snippet']['categoryId']} for item in response['items']]\n",
        "        return pd.DataFrame(trending_list)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur API YouTube : {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_my_history(filepath):\n",
        "    \"\"\"Charge votre fichier Takeout.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        my_history = []\n",
        "        for entry in data:\n",
        "            if 'titleUrl' in entry:\n",
        "                video_id = entry['titleUrl'].split('v=')[-1][:11]\n",
        "                my_history.append({'video_id': video_id})\n",
        "        return pd.DataFrame(my_history)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERREUR : Le fichier '{filepath}' est introuvable. Glissez-le dans le dossier √† gauche sur Colab.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ==========================================\n",
        "# FONCTION PRINCIPALE (Celle qui affiche tout)\n",
        "# ==========================================\n",
        "\n",
        "def analyze_influence():\n",
        "    print(\"üöÄ D√©marrage de l'analyse...\\n\")\n",
        "\n",
        "    # 1. Connexion API\n",
        "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "    # 2. Chargement des donn√©es\n",
        "    df_trending = get_current_trending_videos(youtube)\n",
        "    df_my_history = load_my_history(TAKEOUT_FILE)\n",
        "\n",
        "    if df_trending.empty or df_my_history.empty:\n",
        "        print(\"‚ö†Ô∏è Analyse impossible : donn√©es manquantes.\")\n",
        "        return\n",
        "\n",
        "    # 3. Comparaison (Intersection)\n",
        "    videos_communes = df_my_history[df_my_history['video_id'].isin(df_trending['video_id'])]\n",
        "    nb_communs = len(videos_communes)\n",
        "\n",
        "    # 4. Calcul des scores\n",
        "    influence_perc = (nb_communs / 50) * 100\n",
        "    sensi_score = calculate_sensitivity_score(influence_perc)\n",
        "\n",
        "    # 5. AFFICHAGE DES R√âSULTATS DANS LA CONSOLE\n",
        "    print(\"-\" * 40)\n",
        "    print(\"üìä R√âSULTATS DE L'AUDIT RGPD\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"‚úÖ Vid√©os analys√©es dans votre historique : {len(df_my_history)}\")\n",
        "    print(f\"üî• Vid√©os en commun avec le Top 50 Tendances : {nb_communs}\")\n",
        "    print(f\"üéØ Indice d'influence directe : {influence_perc}%\")\n",
        "    print(f\"\\n‚ö° SCORE DE SENSIBILIT√â (1-10) : {sensi_score}/10\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # 6. Petit message d'interpr√©tation automatique\n",
        "    if sensi_score <= 2:\n",
        "        print(\"Interpr√©tation : Vous √™tes dans une 'Bulle de Niche'. L'algorithme vous conna√Æt trop bien pour vous proposer du contenu g√©n√©raliste.\")\n",
        "    elif sensi_score <= 5:\n",
        "        print(\"Interpr√©tation : Influence mod√©r√©e. Vous suivez quelques tendances mais gardez un profil sp√©cifique.\")\n",
        "    else:\n",
        "        print(\"Interpr√©tation : Profil 'Mainstream'. Vous √™tes fortement synchronis√© avec la culture populaire actuelle.\")\n",
        "\n",
        "# ==========================================\n",
        "# LANCEMENT (Indispensable pour que √ßa s'affiche !)\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_influence()"
      ],
      "metadata": {
        "id": "i9hepRSJ10Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code 5 : Analyse s√©mantique des tags (Influence Th√©matique)\n",
        "\n",
        "**Explication Technique**\n",
        "\n",
        "Ce code extrait les tags (mots-cl√©s) des vid√©os tendances ET de votre historique r√©cent (20 derni√®res vid√©os). Il calcule l'intersection entre ces deux ensembles de tags pour mesurer une \"synchronisation th√©matique\". Contrairement au Code 3 qui compare des vid√©os identiques, celui-ci d√©tecte si vous √™tes expos√© aux m√™mes sujets que la masse, m√™me via des vid√©os diff√©rentes.\n",
        "\n",
        "**Interpr√©tation Critique**\n",
        "\n",
        "C'est l'analyse la plus subtile et dangereuse pour la sant√© mentale. M√™me avec 0% d'influence directe, vous pouvez avoir 30-40% de synchronisation th√©matique. Cela signifie que bien que vous ne regardiez pas les vid√©os virales elles-m√™mes, vous consommez des contenus construits autour des m√™mes triggers √©motionnels : \"clash\", \"drama\", \"urgent\", \"choc\". Ce code r√©v√®le ce que votre oral appelle la \"pollution th√©matique\" : l'algorithme vous sert la toxicit√© virale sous une forme personnalis√©e. Si vos tags communs incluent beaucoup de termes anxiog√®nes ou conflictuels, cela indique que votre bulle, bien que diff√©rente du mainstream, reproduit les m√™mes m√©canismes d'engagement par le stress. C'est la preuve ultime que l'influence de masse existe toujours, elle est juste devenue invisible et insidieuse."
      ],
      "metadata": {
        "id": "rIi3j9vqbYdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CONFIGURATION\n",
        "API_KEY = \"Ins√©rer votre cl√© API ici\"\n",
        "TAKEOUT_FILE = \"Ins√©rer votre fichier watch-history.json ici\"\n",
        "\n",
        "def get_tags_analysis():\n",
        "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "    # 1. R√âCUP√âRER LES TAGS DES TENDANCES (L'air du temps)\n",
        "    print(\"Analyse des th√©matiques tendances en France...\")\n",
        "    request = youtube.videos().list(part=\"snippet\", chart=\"mostPopular\", regionCode=\"FR\", maxResults=50)\n",
        "    res_trending = request.execute()\n",
        "\n",
        "    trending_tags = []\n",
        "    for item in res_trending['items']:\n",
        "        tags = item['snippet'].get('tags', [])\n",
        "        trending_tags.extend([t.lower() for t in tags])\n",
        "\n",
        "    # 2. R√âCUP√âRER LES TAGS DE VOTRE HISTORIQUE (Votre bulle)\n",
        "    print(\"Analyse de vos th√©matiques personnelles...\")\n",
        "    # On prend les 20 derni√®res vid√©os pour voir l'influence r√©cente\n",
        "    df_history = load_my_history(TAKEOUT_FILE).head(20)\n",
        "    my_ids = df_history['video_id'].tolist()\n",
        "\n",
        "    res_my_videos = youtube.videos().list(part=\"snippet\", id=\",\".join(my_ids)).execute()\n",
        "    my_tags = []\n",
        "    for item in res_my_videos['items']:\n",
        "        tags = item['snippet'].get('tags', [])\n",
        "        my_tags.extend([t.lower() for t in tags])\n",
        "\n",
        "    # 3. CALCUL DE LA SYNCHRONISATION\n",
        "    set_trending = set(trending_tags)\n",
        "    set_my = set(my_tags)\n",
        "    common_tags = set_trending.intersection(set_my)\n",
        "\n",
        "    sync_score = (len(common_tags) / len(set_trending)) * 100 if set_trending else 0\n",
        "\n",
        "    # 4. AFFICHAGE\n",
        "    print(f\"\\n--- AUDIT DES TENDANCES CACH√âES ---\")\n",
        "    print(f\"Mots-cl√©s en commun avec les tendances : {list(common_tags)[:10]}...\")\n",
        "    print(f\"Indice de Synchronisation Th√©matique : {sync_score:.2f}%\")\n",
        "\n",
        "    # √âchelle de 1 √† 10 pour la sant√© mentale\n",
        "    mental_impact_score = round(sync_score / 2, 1) # Plus on est synchronis√©, plus l'influence est forte\n",
        "    if mental_impact_score > 10: mental_impact_score = 10.0\n",
        "\n",
        "    print(f\"Score d'exposition aux th√©matiques globales : {mental_impact_score}/10\")\n",
        "\n",
        "# Appel de la fonction\n",
        "get_tags_analysis()"
      ],
      "metadata": {
        "id": "0RYzk0X6CufH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion : Vers une hygi√®ne num√©rique √©clair√©e\n",
        "\n",
        "Ces cinq codes forment un syst√®me d'audit progressif qui d√©voile les m√©canismes cach√©s de l'influence algorithmique. Notre projet d√©montre scientifiquement que la disparition de l'onglet Tendances n'a pas supprim√© l'influence de masse, elle l'a simplement rendue plus sophistiqu√©e et imperceptible. L'algorithme ne nous prot√®ge pas des contenus toxiques ou anxiog√®nes ; il nous les administre sous une forme personnalis√©e, cr√©ant l'illusion du choix tout en maintenant son emprise sur notre attention.\n",
        "\n",
        "Les r√©sultats obtenus r√©v√®lent un double pi√®ge : d'un c√¥t√©, l'hyper-personnalisation nous enferme dans des bulles de niche qui appauvrissent notre diversit√© cognitive ; de l'autre, la synchronisation th√©matique nous expose aux m√™mes m√©canismes viraux (sensationnel, pol√©mique, urgence) que le reste de la population, mais de mani√®re invisible.\n",
        "\n",
        "Gr√¢ce √† l'usage citoyen du RGPD et aux outils de programmation Python, nous avons pu mat√©rialiser cette influence invisible et la quantifier. Ce diagnostic est la premi√®re √©tape vers la rem√©diation : comprendre que l'on est manipul√© permet d'agir. En identifiant les heures de vuln√©rabilit√©, les cha√Ænes qui dominent notre flux, et les th√©matiques anxiog√®nes qui nous sont servies, nous pouvons reprendre le contr√¥le de notre consommation num√©rique.\n",
        "\n",
        "L'enjeu n'est pas de rejeter YouTube, mais de d√©velopper une conscience critique face aux m√©canismes d'engagement. Utiliser les fonctions \"Pas int√©ress√©\", diversifier activement nos sources, et consulter r√©guli√®rement notre audit personnel sont autant de gestes d'hygi√®ne num√©rique essentiels pour pr√©server notre sant√© mentale face √† la logique du \"tout viral\". Ce projet n'est pas une fin en soi, c'est un outil d'√©mancipation qui permet √† chaque utilisateur de devenir acteur de sa propre protection face aux algorithmes."
      ],
      "metadata": {
        "id": "0LeXPZzLbmWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. üü¢ Phrases sur les Points Forts (Les Forces du Code)**\n",
        "\n",
        "\"Notre principale force r√©side dans la m√©thodologie hybride : en croisant l'historique RGPD statique avec la puissance dynamique de l'API YouTube, le code transcende le simple fichier brut pour fournir un diagnostic complet et en temps r√©el de l'influence.\"\n",
        "\"D'un point de vue √©thique, l'architecture est 'Privacy-First' : toutes les analyses sensibles sont effectu√©es localement sur le fichier watch-history.json, assurant que les donn√©es personnelles de l'utilisateur ne quittent jamais le poste de travail.\"\n",
        "\"Le code se distingue par sa capacit√© √† √©valuer l'influence sur trois dimensions : l'influence directe (Top 50), l'influence th√©matique (Tags cach√©s) et l'influence comportementale (Chronobiologie), offrant ainsi une lecture nuanc√©e de la vuln√©rabilit√© algorithmique.\"\n",
        "\"Nous avons fait preuve d'efficacit√© en optimisant les requ√™tes API par lots, ce qui permet de traiter des milliers de vid√©os rapidement tout en respectant les contraintes strictes des quotas impos√©s par Google.\"\n",
        "\n",
        "**2. üî¥ Phrases sur les Points Faibles (Les Limites du Code)**\n",
        "\n",
        "\n",
        "\"Malgr√© la rigueur, le code contient un biais temporel inh√©rent : nous comparons l'historique de l'utilisateur (pouvant remonter √† plusieurs ann√©es) aux tendances actuelles de l'API. Cette asynchronie rend difficile l'affirmation qu'une vid√©o √©tait tendance au moment pr√©cis o√π elle a √©t√© regard√©e.\"\n",
        "\"La d√©pendance √† l'API YouTube repr√©sente une limite mat√©rielle : l'analyse compl√®te d'un historique volumineux est contrainte par le plafond des 10 000 unit√©s/jour de la cl√© gratuite, n√©cessitant potentiellement une fragmentation du traitement.\"\n",
        "\"La source de donn√©es brute du RGPD est imparfaite : le fichier JSON ne distingue pas clairement les Shorts des vid√©os longues ou m√™me des publicit√©s. Une am√©lioration future n√©cessiterait un nettoyage plus agressif pour garantir une pr√©cision optimale dans le calcul des cat√©gories de contenu.\"\n",
        "\"Sur le plan de la robustesse, le code manque encore de m√©canismes de gestion d'erreurs avanc√©s (try...except) pour g√©rer les requ√™tes API qui √©chouent (vid√©o supprim√©e, ID invalide), ce qui pourrait interrompre l'analyse pour certains jeux de donn√©es.‚Äù\n"
      ],
      "metadata": {
        "id": "pmp7fMFGs5_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html *.ipynb"
      ],
      "metadata": {
        "id": "OwAVlO3LIO27"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}